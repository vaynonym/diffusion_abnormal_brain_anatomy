run:
  batch_size: 2
  input_image_downsampling_factors: [2, 2, 2] # (160, 224, 160) ==>
  input_image_crop_roi: [80,112,80]
  evaluation_intervall: 0.1
  dataset: "LDM100K"
  target_data: "mask"
  dataset_size: 5000

auto_encoder: 
  spatial_dims: 3
  in_channels: 33
  out_channels: 33
  latent_channels: 3
  num_channels: [64,128,128]
  num_res_blocks: 2
  norm_num_groups: 32
  attention_levels: [False, False, False]
  with_encoder_nonlocal_attn: False
  with_decoder_nonlocal_attn: False

autoencoder_training: 
  n_epochs: 40
  learning_rate: 0.00025
  autoencoder_warm_up_n_epochs: 3

patch_discrim: 
  spatial_dims: 3
  num_layers_d: 3
  num_channels: 64
  in_channels: 33
  out_channels: 33

diffusion_model_unet: 
  spatial_dims: 3
  in_channels: 3
  out_channels: 3
  num_res_blocks: 2
  num_channels: [128, 256, 512]
  attention_levels: [False, True, True]
  num_head_channels: [0, 256, 512]
  norm_num_groups: 32
  upcast_attention: True
  resblock_updown: True
  with_conditioning: True
  cross_attention_dim: 1

diffusion_model_unet_training:
  n_epochs: 10
  learning_rate: 0.00002